{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPJAJVaijDutbXFFp9kIaow",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gauthampharish/OCR/blob/main/contour_based_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "id": "aRtL16Pf32WF",
        "outputId": "5de65fc5-8f24-4044-89f4-830c35798def",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.6)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.14.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install emnist"
      ],
      "metadata": {
        "id": "5N4ZYUrB4Oxt",
        "outputId": "9fc1dd9e-4fee-44dc-de2b-83ac88b2f8c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emnist in /usr/local/lib/python3.10/dist-packages (0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from emnist) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from emnist) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from emnist) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->emnist) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->emnist) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->emnist) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->emnist) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZSpuWaXhZyzC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from kerastuner.tuners import RandomSearch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import emnist\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from emnist import extract_training_samples\n",
        "train_images, train_labels = extract_training_samples('byclass')"
      ],
      "metadata": {
        "id": "pGdn2k_s4orh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from emnist import extract_test_samples\n",
        "test_images, test_labels = extract_test_samples('byclass')\n"
      ],
      "metadata": {
        "id": "Bj8Ng2Au43T4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_images = tf.keras.utils.normalize(train_images, axis = 1)\n",
        "test_images = tf.keras.utils.normalize(test_images, axis = 1)\n",
        "\n",
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "test_images = np.expand_dims(test_images, axis=3)"
      ],
      "metadata": {
        "id": "bgEQ48ks3Xqu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rotation_range_val = 15\n",
        "width_shift_val = 0.10\n",
        "height_shift_val = 0.10"
      ],
      "metadata": {
        "id": "x1-4J5c448P6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rotation_range = rotation_range_val,\n",
        "                             width_shift_range = width_shift_val,\n",
        "                             height_shift_range = height_shift_val)"
      ],
      "metadata": {
        "id": "Jcv1l2Pw4_Z5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen.fit(train_images.reshape(train_images.shape[0], 28, 28, 1))"
      ],
      "metadata": {
        "id": "zh-B596o3Zlz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator()\n",
        "test_datagen.fit(test_images.reshape(test_images.shape[0], 28, 28, 1))\n",
        "test_datagen"
      ],
      "metadata": {
        "id": "HUJwsSxx5FpJ",
        "outputId": "ef86b0db-9b57-46bf-eb40-3a87db43e2ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.preprocessing.image.ImageDataGenerator at 0x7d59efff3cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Reshape((-1, 64)))\n",
        "    model.add(layers.LSTM(128))\n",
        "    model.add(layers.Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(62, activation='softmax'))\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "yMFDwqiJ3cDf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "from kerastuner.tuners import RandomSearch\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set up the tuner with a temporary directory in Colab\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=2,\n",
        "    executions_per_trial=2,\n",
        "    directory='/content/drive/MyDrive/colab_temp',  # You can change this directory as needed\n",
        "    project_name='helloworld'\n",
        ")\n"
      ],
      "metadata": {
        "id": "3OtKgowK3eN9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels_one_hot = to_categorical(train_labels, num_classes=62)\n",
        "test_labels_one_hot = to_categorical(test_labels, num_classes=62)"
      ],
      "metadata": {
        "id": "7dVM27Ha60bI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for the best hyperparameters\n",
        "tuner.search(train_datagen.flow(train_images, train_labels_one_hot, batch_size=1024),\n",
        "             validation_data=test_datagen.flow(test_images, test_labels_one_hot, batch_size=32),\n",
        "             epochs=8)\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n"
      ],
      "metadata": {
        "id": "Rys-Xq5i6Fu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Replace 'saved_model_path' with the path to your saved model directory\n",
        "saved_model_path = '/content/your_model.h5'\n",
        "\n",
        "# Load the model\n",
        "model = load_model(saved_model_path)"
      ],
      "metadata": {
        "id": "aafACEsu9eNQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameters\n",
        "model = tuner.hypermodel.build(best_hps)"
      ],
      "metadata": {
        "id": "lllsEV7Y6HK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with the training data\n",
        "model.fit(train_datagen.flow(train_images, train_labels_one_hot, batch_size=1024), epochs=15)\n"
      ],
      "metadata": {
        "id": "OVq__q2L3f_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model with the testing data\n",
        "model.evaluate(test_datagen.flow(test_images, test_labels_one_hot, batch_size=32))"
      ],
      "metadata": {
        "id": "R5bGFm6y3hKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model, save_model\n",
        "\n",
        "# Save the model\n",
        "model.save(\"your_model.h5\")"
      ],
      "metadata": {
        "id": "4cYNVkEZKcvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "img = cv2.imread('/content/new.jpg')\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply adaptive thresholding\n",
        "thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,11,30)\n",
        "\n",
        "# Find contours\n",
        "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "characters = []\n",
        "for contour in contours:\n",
        "    # Get bounding box for each contour\n",
        "    x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "    # Extract the character\n",
        "    character = gray[y:y+h, x:x+w]\n",
        "\n",
        "    # Resize to a standard size (e.g., 28x28)\n",
        "    character = cv2.resize(character, (28, 28))\n",
        "\n",
        "    characters.append(character)\n",
        "\n",
        "print(f'Number of characters: {len(characters)}')\n",
        "\n",
        "# Save the characters as numpy arrays\n",
        "characters_array = []\n",
        "for i, char in enumerate(characters):\n",
        "    # Convert the character to a numpy array\n",
        "    char_array = np.array(char)\n",
        "\n",
        "    # Append the character array to the list of characters\n",
        "    characters_array.append(char_array)\n",
        "\n",
        "# Convert the list of characters to a numpy array\n",
        "characters_array = np.array(characters_array)\n",
        "\n"
      ],
      "metadata": {
        "id": "tfTbHip-8NMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def index_to_char(index):\n",
        "    if index < 10:\n",
        "        return str(index)\n",
        "    elif index < 36:\n",
        "        return chr(index - 10 + ord('A'))\n",
        "    else:\n",
        "        return chr(index - 36 + ord('a'))\n",
        "\n",
        "# Predict the character for each image\n",
        "for i, char_img in enumerate(characters_array):\n",
        "    # Preprocess the image\n",
        "    char_img = char_img.reshape(1, 28, 28, 1)\n",
        "    char_img = char_img.astype('float32')\n",
        "    char_img /= 255\n",
        "\n",
        "    # Predict the character\n",
        "    prediction = model.predict([char_img])\n",
        "    predicted_index = np.argmax(prediction)\n",
        "    predicted_char = index_to_char(predicted_index)\n",
        "\n",
        "    print(f'Character {i}: {predicted_char}')"
      ],
      "metadata": {
        "id": "hlG_MDu-3j5a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}