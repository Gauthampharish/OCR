{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyK5ik7XASb183mxk3DG2w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gauthampharish/OCR/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSpuWaXhZyzC",
        "outputId": "79c3432c-f724-4752-ec4b-5beef775bbb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras.layers import Dense, Flatten, Softmax\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BtrIFwA0JV11"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emnist\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhqfl-EEZ7J1",
        "outputId": "d5c3b9e4-80b6-4ce1-e2e9-55cc20e2c871"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emnist\n",
            "  Downloading emnist-0.0-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from emnist) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from emnist) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from emnist) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->emnist) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->emnist) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->emnist) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->emnist) (2023.7.22)\n",
            "Installing collected packages: emnist\n",
            "Successfully installed emnist-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import emnist"
      ],
      "metadata": {
        "id": "KScN6TvWmRvO"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from emnist import extract_training_samples\n",
        "train_x, train_y = extract_training_samples('letters')\n",
        "\n",
        "train_x = train_x /255.0\n",
        "train_y = train_y - 1"
      ],
      "metadata": {
        "id": "K5e0EnzAaYlD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cafed96-8fb3-4590-c7f2-71892fc8c782"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading emnist.zip: 536MB [00:06, 88.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from emnist import extract_test_samples\n",
        "test_x, test_y = extract_test_samples('letters')\n",
        "test_x = test_x / 255.0\n",
        "test_y = test_y - 1"
      ],
      "metadata": {
        "id": "WO0t9aliasuY"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()"
      ],
      "metadata": {
        "id": "L0IMXilrbFcB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(layers.Input(shape=(28, 28, 1)))\n",
        "\n",
        "# Convolutional Layer 1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Convolutional Layer 2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten Layer\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Fully Connected Layer 1\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "# Dropout Layer\n",
        "model.add(layers.Dropout(0.5))  # You can adjust the dropout rate as needed\n",
        "\n",
        "# Output Layer\n",
        "model.add(layers.Dense(26, activation='softmax'))  # Assuming 26 classes for the English alphabet\n",
        "\n",
        "# Compile the model\n",
        "\n",
        "# Print a summary of the model architecture\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4k04Cpgmfm0",
        "outputId": "ea697ac5-0d15-4f1d-b81d-0f2cb5e54a1f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 3, 3, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               590336    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 26)                3354      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 752026 (2.87 MB)\n",
            "Trainable params: 752026 (2.87 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_x, train_y, validation_split = 0.2, batch_size = 30, epochs = 13)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz4B-nfMmkJ3",
        "outputId": "5845feda-295c-4dc5-f23a-47052f8d1e2d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "3328/3328 [==============================] - 241s 72ms/step - loss: 0.5141 - accuracy: 0.8408 - val_loss: 0.2269 - val_accuracy: 0.9204\n",
            "Epoch 2/13\n",
            "3328/3328 [==============================] - 235s 71ms/step - loss: 0.2406 - accuracy: 0.9246 - val_loss: 0.1944 - val_accuracy: 0.9356\n",
            "Epoch 3/13\n",
            "3328/3328 [==============================] - 234s 70ms/step - loss: 0.1984 - accuracy: 0.9362 - val_loss: 0.1918 - val_accuracy: 0.9389\n",
            "Epoch 4/13\n",
            "3328/3328 [==============================] - 219s 66ms/step - loss: 0.1723 - accuracy: 0.9415 - val_loss: 0.2027 - val_accuracy: 0.9389\n",
            "Epoch 5/13\n",
            "3328/3328 [==============================] - 212s 64ms/step - loss: 0.1551 - accuracy: 0.9478 - val_loss: 0.1911 - val_accuracy: 0.9419\n",
            "Epoch 6/13\n",
            "3328/3328 [==============================] - 211s 64ms/step - loss: 0.1400 - accuracy: 0.9512 - val_loss: 0.2017 - val_accuracy: 0.9440\n",
            "Epoch 7/13\n",
            "3328/3328 [==============================] - 218s 65ms/step - loss: 0.1290 - accuracy: 0.9540 - val_loss: 0.2071 - val_accuracy: 0.9398\n",
            "Epoch 8/13\n",
            "3328/3328 [==============================] - 218s 66ms/step - loss: 0.1192 - accuracy: 0.9565 - val_loss: 0.2101 - val_accuracy: 0.9407\n",
            "Epoch 9/13\n",
            "3328/3328 [==============================] - 211s 63ms/step - loss: 0.1123 - accuracy: 0.9582 - val_loss: 0.2137 - val_accuracy: 0.9440\n",
            "Epoch 10/13\n",
            "3328/3328 [==============================] - 211s 64ms/step - loss: 0.1040 - accuracy: 0.9607 - val_loss: 0.2304 - val_accuracy: 0.9435\n",
            "Epoch 11/13\n",
            "3328/3328 [==============================] - 229s 69ms/step - loss: 0.0997 - accuracy: 0.9623 - val_loss: 0.2667 - val_accuracy: 0.9359\n",
            "Epoch 12/13\n",
            "3328/3328 [==============================] - 226s 68ms/step - loss: 0.0980 - accuracy: 0.9626 - val_loss: 0.2578 - val_accuracy: 0.9398\n",
            "Epoch 13/13\n",
            "3328/3328 [==============================] - 213s 64ms/step - loss: 0.0940 - accuracy: 0.9650 - val_loss: 0.2720 - val_accuracy: 0.9397\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7862a7717c70>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model, save_model\n",
        "\n",
        "# Save the model\n",
        "model.save(\"your_model.h5\")"
      ],
      "metadata": {
        "id": "_oF7bhnUkv-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0835b3e2-9c07-4e13-886c-d6166c00f75d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dilhelh/opencv-text-detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02EviC0cJv-7",
        "outputId": "aa8bf5b7-25ca-4153-df1f-12cceae7fc8b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'opencv-text-detection' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/opencv-text-detection/text_detection.py --image /content/opencv-text-detection/images/lebron_james.jpg \\\n",
        "\t--east /content/opencv-text-detection/frozen_east_text_detection.pb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y29R_HrLKBvn",
        "outputId": "f65274b2-075d-41f5-c23d-b49b412ec24b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading EAST text detector...\n",
            "[INFO] text detection took 0.923866 seconds\n",
            "qt.qpa.xcb: could not connect to display \n",
            "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"/usr/local/lib/python3.10/dist-packages/cv2/qt/plugins\" even though it was found.\n",
            "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
            "\n",
            "Available platform plugins are: xcb.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import cv2\n",
        "import time\n",
        "from imutils.object_detection import non_max_suppression\n",
        "\n",
        "def east_detect(image):\n",
        "    layerNames = [\n",
        "        \"feature_fusion/Conv_7/Sigmoid\",\n",
        "        \"feature_fusion/concat_3\"]\n",
        "\n",
        "    orig = image.copy()\n",
        "\n",
        "    if len(image.shape) == 2:\n",
        "        # Convert grayscale image to BGR by duplicating the channel\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    (H, W) = image.shape[:2]\n",
        "\n",
        "    # set the new width and height and then determine the ratio in change\n",
        "    # for both the width and height: Should be multiple of 32\n",
        "    (newW, newH) = (320, 320)\n",
        "\n",
        "    rW = W / float(newW)\n",
        "    rH = H / float(newH)\n",
        "\n",
        "    # resize the image and grab the new image dimensions\n",
        "    image = cv2.resize(image, (newW, newH))\n",
        "\n",
        "    (H, W) = image.shape[:2]\n",
        "\n",
        "    net = cv2.dnn.readNet(cv2.samples.findFile(\"/content/opencv-text-detection/frozen_east_text_detection.pb\"))\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H), (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    net.setInput(blob)\n",
        "\n",
        "    (scores, geometry) = net.forward(layerNames)\n",
        "\n",
        "    (numRows, numCols) = scores.shape[2:4]\n",
        "    rects = []\n",
        "    confidences = []\n",
        "    # loop over the number of rows\n",
        "    for y in range(0, numRows):\n",
        "        # extract the scores (probabilities), followed by the geometrical\n",
        "        # data used to derive potential bounding box coordinates that\n",
        "        # surround text\n",
        "        scoresData = scores[0, 0, y]\n",
        "        xData0 = geometry[0, 0, y]\n",
        "        xData1 = geometry[0, 1, y]\n",
        "        xData2 = geometry[0, 2, y]\n",
        "        xData3 = geometry[0, 3, y]\n",
        "        anglesData = geometry[0, 4, y]\n",
        "\n",
        "        for x in range(0, numCols):\n",
        "            # if our score does not have sufficient probability, ignore it\n",
        "            # Set minimum confidence as required\n",
        "            if scoresData[x] < 0.5:\n",
        "                continue\n",
        "            # compute the offset factor as our resulting feature maps will\n",
        "            #  x smaller than the input image\n",
        "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
        "            # extract the rotation angle for the prediction and then\n",
        "            # compute the sin and cosine\n",
        "            angle = anglesData[x]\n",
        "            cos = np.cos(angle)\n",
        "            sin = np.sin(angle)\n",
        "            # use the geometry volume to derive the width and height of\n",
        "            # the bounding box\n",
        "            h = xData0[x] + xData2[x]\n",
        "            w = xData1[x] + xData3[x]\n",
        "            # compute both the starting and ending (x, y)-coordinates for\n",
        "            # the text prediction bounding box\n",
        "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
        "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
        "            startX = int(endX - w)\n",
        "            startY = int(endY - h)\n",
        "            # add the bounding box coordinates and probability score to\n",
        "            # our respective lists\n",
        "            rects.append((startX, startY, endX, endY))\n",
        "            confidences.append(scoresData[x])\n",
        "\n",
        "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
        "\n",
        "    # Initialize a list to store characters in MNIST-like format\n",
        "    characters = []\n",
        "\n",
        "    # Loop over the bounding boxes\n",
        "    for (startX, startY, endX, endY) in boxes:\n",
        "        # Check if the bounding box is valid and not empty\n",
        "        if startX < endX and startY < endY:\n",
        "            # Extract the region of interest (ROI) for each character\n",
        "            roi = orig[startY:endY, startX:endX]\n",
        "\n",
        "            # Check if the ROI is large enough to resize to 28x28\n",
        "            if roi.shape[0] > 0 and roi.shape[1] > 0:\n",
        "                # Resize the character to MNIST image size (28x28)\n",
        "                mnist_character = cv2.resize(roi, (28, 28))\n",
        "\n",
        "                # Convert to grayscale\n",
        "                mnist_character = cv2.cvtColor(mnist_character, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                # Apply thresholding to binarize the image\n",
        "                _, mnist_character = cv2.threshold(mnist_character, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "                characters.append(mnist_character)\n",
        "    print(characters,\"k\")\n",
        "    # Save the characters as individual image files (optional)\n",
        "    for i, character in enumerate(characters):\n",
        "        character_filename = f\"character_{i}.png\"\n",
        "        cv2.imwrite(character_filename, character)\n",
        "\n",
        "    print(time.time() - start)\n",
        "    return characters\n",
        "\n",
        "image = cv2.imread(\"/content/images.png\")\n",
        "out_image = east_detect(image)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDiabOecJXu7",
        "outputId": "8e5f0490-1ed4-4ee2-e195-a15db978c326"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255,   0, 255, 255, 255,   0,\n",
            "        255, 255, 255,   0, 255, 255, 255,   0,   0, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255,   0,   0,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255,   0,   0,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255,   0,   0,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0,   0,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0,\n",
            "        255, 255, 255, 255, 255, 255, 255,   0, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0,\n",
            "        255, 255, 255, 255,   0, 255, 255,   0, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255]], dtype=uint8), array([[255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255,   0,   0,   0, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255,   0, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255,   0, 255, 255,   0,   0,   0, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255,   0,   0, 255, 255,   0,   0,   0, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255,   0,   0, 255, 255,   0, 255,   0, 255, 255,   0,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255,   0,   0, 255, 255,   0, 255,   0, 255, 255,   0,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255, 255,   0,\n",
            "        255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255, 255,   0,\n",
            "        255, 255, 255,   0, 255, 255, 255,   0, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0,\n",
            "        255, 255, 255,   0, 255, 255, 255,   0, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0,\n",
            "        255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255,   0, 255, 255, 255,   0, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255,   0, 255, 255, 255,   0, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255]], dtype=uint8)] k\n",
            "0.7783222198486328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load your pretrained model\n",
        "model = load_model('/content/your_model (1).h5')\n",
        "\n",
        "# binary_images is your array of binary images (MNIST-like)\n",
        "\n",
        "print(out_image)\n",
        "# Create an empty list to store predictions\n",
        "predictions = []\n",
        "desired_size = (28, 28)\n",
        "\n",
        "# Resize the binary image to the desired size\n",
        "resized_image = cv2.resize(binary_image, desired_size, interpolation=cv2.INTER_LINEAR)\n",
        "# Loop through the binary images\n",
        "for binary_image in out_image:\n",
        "    # Ensure that the shape of the binary image matches the expected input shape of your model\n",
        "    if binary_image.shape != (28, 28):\n",
        "       resized_image = cv2.resize(binary_image, desired_size, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "\n",
        "    # Add a batch dimension (usually 1 image in the batch)\n",
        "    input_image = np.expand_dims(resized_image, axis=0)\n",
        "\n",
        "    # Make predictions using the model\n",
        "    result = model.predict(input_image)\n",
        "\n",
        "    predictions.append(result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfWn3wGsSsUW",
        "outputId": "caf26f46-8387-47ee-80a0-7e7a94c96b72"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255,   0, 255, 255, 255,   0,\n",
            "        255, 255, 255,   0, 255, 255, 255,   0,   0, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255,   0,   0,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255,   0,   0,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255,   0,   0,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0,   0,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0,\n",
            "        255, 255, 255, 255, 255, 255, 255,   0, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0,\n",
            "        255, 255, 255, 255,   0, 255, 255,   0, 255, 255, 255,   0, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255]], dtype=uint8), array([[255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255,   0,   0,   0, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255,   0, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255,   0, 255, 255,   0,   0,   0, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255,   0,   0, 255, 255,   0,   0,   0, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255,   0,   0, 255, 255,   0, 255,   0, 255, 255,   0,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255,   0,   0, 255, 255,   0, 255,   0, 255, 255,   0,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255, 255,   0,\n",
            "        255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255, 255,   0,\n",
            "        255, 255, 255,   0, 255, 255, 255,   0, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0,\n",
            "        255, 255, 255,   0, 255, 255, 255,   0, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,   0,\n",
            "        255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255,   0, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255,   0, 255, 255, 255,   0, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255,   0, 255, 255, 255,   0, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255],\n",
            "       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
            "        255, 255]], dtype=uint8)]\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "# Convert the output predictions to alphabets\n",
        "def predictions_to_alphabets(predictions):\n",
        "    alphabets = string.ascii_uppercase  # A-Z\n",
        "\n",
        "    converted_predictions = []\n",
        "\n",
        "    for prediction in predictions:\n",
        "        max_prob_index = np.argmax(prediction)\n",
        "        alphabet = alphabets[max_prob_index]\n",
        "        converted_predictions.append(alphabet)\n",
        "\n",
        "    return converted_predictions"
      ],
      "metadata": {
        "id": "Rc2F3mztV7yp"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_to_alphabets(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdW4ZAgqV-HK",
        "outputId": "232c5d47-31c4-4628-ecae-119afe707a49"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B', 'B']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}
